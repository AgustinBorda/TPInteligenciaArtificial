1- De entre los algoritmos de hill climbing, hill climbing con reinicios aleatorios y simulated annealing(con su funcion de scheduling por defecto)
el mejor es hill climbing con reinicios aleatorios, esta es mejor que el hill climbing normal, ya que hill climbing con reinicios aleatorios primero realiza
una ejecucion del hill climbing normal, para despues iniciar con los reinicios aleatorios, por lo que para toda ejecucion de hill climbing con reinicios aleatorios,
se obtendra un resultado igual o mejor que con hill climbing (para el mismo seed). Para el caso de simulated annealing, la funcion de schedule por defecto se reduce muy rapido
para la magnitud de los casos de test dados, por lo que sin modificarla, los hill climbing siempre dan resultados mejor que simulated annealing,
por ejemplo, para el caso de 5000 elementos, los hill climbing van desde un valor de 48000 a 100000, mientras que para simulated annealing los valores se mueven de 25000 a 40000,
con un optimo de 276457. Sin embargo, si se le da a simulated annealing una funcion de schedule apropiada para estos casos, se convierte en la mejor opcion disponible, ya que otorga mucho
mejores resultados que hill climbing y hill climbing con reinicios aleatorios (para el caso anterior los valores van desde 190000 hasta 230000) y funciona mucho mas rapido que hill climbing con reinicios aleatorios (2,1 minutos contra 17,34 minutos).


2- Simulated annealing con la funcion de schedule por defecto no necesitaba ser optimizada en tiempo (esto se realizaria haciendo que la funcion se decremente mas rapido, o que empiece desde 
numeros mas bajos,o reducir el limite de tiempo, estas 3 cosas acelerarian la convergencia),
 pero necesita obtener mejores resultados para poder ser una opcion viable, por lo que se opto por reducir el decremento de la funcion , aumentar el tiempo limite de esta y 
hacer que inicie desde puntos mas altos, estas cosas no damnifican demasiado al tiempo de convergencia (para el caso de 5000 elementos es de 2,1 minutos) y logran que los resultados que devuelve
el algoritmo se acerquen mucho mas al resultado que sus algoritmos competidores. Por ejemplo, para el caso de 5000 elementos se planteo parametrizar la funcion de schedule original con
k=800, lam=0.0005 y limit=4000, originalmente el limite era de 10000, pero gracias a los ploteos de la funcion, se observo que a partir de 4000, los resultados se estancaban, hasta que 
el algoritmo finalizaba.


3- 
  -El algoritmo selecciona de la siguiente forma: Ordena a los individuos en base al operador de seleccion que tenga instanciada el algoritmo, luego pone todos 
los individuos ordenados en la lista de offspring y luego clona la poblacion con fines estadisticos.

  -El crossover es realizado de esta forma: se empareja cada individuo de indice par con su sucesor en la lista offspring y a cada indice impar con su antecesor,
luego se genera un numero aleatorio, y si este es menor a CXPB (la probabilidad de crossover) se llama al operador mate con la pareja de individuos,
esta funcion deberia fusionarlos y devolverlos, pero siendo ambos una fusion de la pareja original, luego se borran los valores viejos de fitness de la pareja, ya que 
esta ahora no existe.

  -Finalmente, la mutacion consiste en: generar un numero aleatorio para cada individuo del offspring, y si este numero es menor a MTPB (la probabilidad mutacion)
se invoca al operador mutate con el individuo en cuestion, este modifica al individuo de una forma leve por lo general, ya que una mutacion deberia ser un pequeno cambio en la estructura
de un individuo, despues de aplicarlo, se elimina el valor viejo de fitness del individuo.

Los individuos generados por crossover o mutacion no tienen una fitness valida, por ello, el algoritmo calcula el valor de fitness de cada individuo que no lo posea ya y luego se lo asigna,
finalmente se le asigna a la poblacion actual el offspring, reemplazando a la generacion anterior por la actual. 

4-Basado en la evidencia otorgada con los tests efectuados, podriamos concluir que el enfoque de simulated annealing es superior en casos grandes(de 100 elementos o mas), dado que converge a valores
mas cercanos al optimo y en menos tiempo, ademas de tener un rasgo de dispersion menor de una ejecucion de test a otra. Por otra parte,
en casos chicos los algoritmos geneticos vencen, ya que para lograr resultados parecidos, annealing demora mas tiempo que un ga (lo opuesto que pasa en casos grandes).
Estas conclusiones se extraen de casos de tests con unas implementaciones y algoritmos particulares, por lo que hay un margen de error para las afirmaciones previas, puesto que
pueden existir mejores funciones de fitness y mejores representaciones del problema de la mochila en grandes dimensiones en los ga, o mejores funciones de schedule para pequenos casos
en simulated annealing.
Una cosa a favor de los algoritmos evolutivos es que no es necesario definir reglas de avance ni nada parecido,
ya que la fitness deberia moderar eso, esto lleva a que en los ga haya menos posibilidades de errores por parte del programador. Por otra parte, simulated annealing es mucho mas
eficiente en el uso de memoria que un ga.


4-
Implementacion de las n-reinas:
Clausulas ejemplo para n=4:
 - Solo puede haber una reina por fila o columna:
    - (X11 | X12 | X13 | X14) & (X21 | X22 | X23 | X24) & etc...
    - forall m in [1:4]: forall i!=j: X(m,i) -> ~X(m,j) and forall i!=j: X(i,m) -> ~X(j,m)

 - Solo puede haber una reina por diagonal
   - (X11 | X22 | X33 | X44) & (X12 | X23 | X34) & etc...
  El algoritmo DPLL definitivamente es superior a enumeracion de modelos. En nuestras pruebas pudimos encontrar que para n > 5 enumeracion de modelos se vuelve extremadamente
lento para encontrar una solucion (3 minutos para n=5) lo que tiene mucho sentido dada que el algoritmo es O(2^n)
  Por otro lado, DPLL pudo lograr resolver sin problemas y en un tiempo razonable instancias de n <= 12, para valores mas grandes de nuevo, la demora es muy grande.
